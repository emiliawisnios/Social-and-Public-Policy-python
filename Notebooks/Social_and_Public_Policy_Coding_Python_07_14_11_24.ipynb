{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7lu6wcxC0etiAiwxKtXAn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emiliawisnios/Social-and-Public-Policy-python/blob/main/Notebooks/Social_and_Public_Policy_Coding_Python_07_14_11_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In today's class we will focus on text documents processing.\n",
        "\n",
        "Next time we will work on data scraping."
      ],
      "metadata": {
        "id": "v4rZr3_VHQb4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment setup"
      ],
      "metadata": {
        "id": "7iaYnZ3rJK6D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJAib5HIHLXw",
        "outputId": "8899f1bb-95aa-44ae-bf42-9c21fc4c1fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "# Required libraries for text processing\n",
        "# !pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File Handling"
      ],
      "metadata": {
        "id": "BbpVqCljJQpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Text Files\n",
        "\n",
        "In political science research, we often work with various text documents like:\n",
        "- Policy documents\n",
        "- Speech transcripts\n",
        "- Legislative texts\n",
        "- Social media data\n",
        "\n",
        "\n",
        "Let's learn how to handle these files in Python."
      ],
      "metadata": {
        "id": "-y-2IuTUJkc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Basic file reading\n",
        "def read_simple_file(filename):\n",
        "    \"\"\"\n",
        "    Basic function to read a text file\n",
        "    \"\"\"\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        return file.read()"
      ],
      "metadata": {
        "id": "6u8Q4DKyJP_M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXERCISE 1:\n",
        "\n",
        "Create a text file named `speech.txt` with any political speech. Try reading it using the function above.\n"
      ],
      "metadata": {
        "id": "f0uOxb8jJqvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "read_simple_file('/content/speech.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "fH7jq8m0H8YT",
        "outputId": "d18592f3-32e2-4a8d-9489-50829909791b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ksiƒôga pierwsza\\n\\n\\n\\nGospodarstwo\\n\\nPowr√≥t panicza ‚Äî Spotkanie siƒô pierwsze w pokoiku, drugie u sto≈Çu ‚Äî Wa≈ºna Sƒôdziego nauka o grzeczno≈õci ‚Äî Podkomorzego uwagi polityczne nad modami ‚Äî PoczƒÖtek sporu o Kusego i Soko≈Ça ‚Äî ≈ªale Wojskiego ‚Äî Ostatni Wo≈∫ny Trybuna≈Çu ‚Äî Rzut oka na √≥wczesny stan polityczny Litwy i Europy\\n\\n    Litwo! Ojczyzno moja! ty jeste≈õ jak zdrowie:\\nIle ciƒô trzeba ceniƒá, ten tylko siƒô dowie,\\nKto ciƒô straci≈Ç. Dzi≈õ piƒôkno≈õƒá twƒÖ w ca≈Çej ozdobie\\nWidzƒô i opisujƒô, bo tƒôskniƒô po tobie.\\n\\n    Panno ≈õwiƒôta, co Jasnej bronisz Czƒôstochowy\\nI w Ostrej ≈õwiecisz Bramie! Ty, co gr√≥d zamkowy\\nNowogr√≥dzki ochraniasz z jego wiernym ludem!\\nJak mnie dziecko do zdrowia powr√≥ci≈Ça≈õ cudem\\n(Gdy od p≈ÇaczƒÖcej matki, pod TwojƒÖ opiekƒô\\nOfiarowany, martwƒÖ podnios≈Çem powiekƒô;\\nI zaraz mog≈Çem pieszo, do Twych ≈õwiƒÖty≈Ñ progu\\nI≈õƒá za wr√≥cone ≈ºycie podziƒôkowaƒá Bogu),\\nTak nas powr√≥cisz cudem na Ojczyzny ≈Çono.\\nTymczasem przeno≈õ mojƒÖ duszƒô utƒôsknionƒÖ\\nDo tych pag√≥rk√≥w le≈õnych, do tych ≈ÇƒÖk zielonych,\\nSzeroko nad b≈Çƒôkitnym Niemnem rozciƒÖgnionych;\\nDo tych p√≥l malowanych zbo≈ºem rozmaitem,\\nWyz≈Çacanych pszenicƒÖ, posrebrzanych ≈ºytem;\\nGdzie bursztynowy ≈õwierzop, gryka jak ≈õnieg bia≈Ça,\\nGdzie panie≈Ñskim rumie≈Ñcem dziƒôcielina pa≈Ça,\\nA wszystko przepasane jakby wstƒôgƒÖ, miedzƒÖ\\nZielonƒÖ, na niej z rzadka ciche grusze siedzƒÖ.\\n\\n    ≈ör√≥d takich p√≥l przed laty, nad brzegiem ruczaju,\\nNa pag√≥rku niewielkim, we brzozowym gaju,\\nSta≈Ç dw√≥r szlachecki, z drzewa, lecz podmurowany;\\n≈öwieci≈Çy siƒô z daleka pobielane ≈õciany,\\nTym bielsze, ≈ºe odbite od ciemnej zieleni\\nTopoli, co go broniƒÖ od wiatr√≥w jesieni.\\nDom mieszkalny niewielki, lecz zewszƒÖd chƒôdogi,\\nI stodo≈Çƒô mia≈Ç wielkƒÖ, i przy niej trzy stogi\\nU≈ºƒÖtku, co pod strzechƒÖ zmie≈õciƒá siƒô nie mo≈ºe.\\nWidaƒá, ≈ºe okolica obfita we zbo≈ºe,\\nI widaƒá z liczby kopic, co wzd≈Çu≈º i wszerz smug√≥w\\n≈öwiecƒÖ gƒôsto jak gwiazdy, widaƒá z liczby p≈Çug√≥w\\nOrzƒÖcych wcze≈õnie ≈Çany ogromne ugoru,\\nCzarnoziemne, zapewne nale≈ºne do dworu,\\nUprawne dobrze na kszta≈Çt ogrodowych grzƒÖdek:\\n≈ªe w tym domu dostatek mieszka i porzƒÖdek.\\nBrama na wciƒÖ≈º otwarta przechodniom og≈Çasza,\\n≈ªe go≈õcinna, i wszystkich w go≈õcinƒô zaprasza.\\n\\n    W≈Ça≈õnie dwukonnƒÖ brykƒÖ wjecha≈Ç m≈Çody panek\\nI obieg≈Çszy dziedziniec zawr√≥ci≈Ç przed ganek.\\nWysiad≈Ç z powozu; konie porzucone same,\\nSzczypiƒÖc trawƒô ciƒÖgnƒô≈Çy powoli pod bramƒô.\\nWe dworze pusto: bo drzwi od ganku zamkniƒôto\\nZaszczepkami i ko≈Çkiem zaszczepki przetkniƒôto.\\nPodr√≥≈ºny do folwarku nie bieg≈Ç s≈Çug zapytaƒá,\\nOdemknƒÖ≈Ç, wbieg≈Ç do domu, pragnƒÖ≈Ç go powitaƒá.\\nDawno domu nie widzia≈Ç, bo w dalekim mie≈õcie\\nKo≈Ñczy≈Ç nauki, ko≈Ñca doczeka≈Ç nareszcie.\\nWbiega i okiem chciwie ≈õciany starodawne\\nOglƒÖda czule, jako swe znajome dawne.\\nTe≈º same widzi sprzƒôty, te≈º same obicia,\\nZ kt√≥rymi siƒô zabawiaƒá lubi≈Ç od powicia,\\nLecz mniej wielkie, mniej piƒôkne ni≈º siƒô dawniej zda≈Çy.\\nI te≈º same portrety na ≈õcianach wisia≈Çy:\\nTu Ko≈õciuszko w czamarce krakowskiej, z oczyma\\nPodniesionymi w niebo, miecz oburƒÖcz trzyma;\\nTakim by≈Ç, gdy przysiƒôga≈Ç na stopniach o≈Çtarz√≥w,\\n≈ªe tym mieczem wypƒôdzi z Polski trzech mocarz√≥w,\\nAlbo sam na nim padnie. Dalej w polskiej szacie\\nSiedzi Rejtan, ≈ºa≈Ço≈õny po wolno≈õci stracie;\\nW rƒôku trzyma n√≥≈º ostrzem zwr√≥cony do ≈Çona,\\nA przed nim le≈ºy Fedon i ≈ºywot Katona.\\nDalej Jasi≈Ñski, m≈Çodzian piƒôkny i posƒôpny;\\nObok Korsak, towarzysz jego nieodstƒôpny:\\nStojƒÖ na sza≈Ñcach Pragi, na stosach Moskali,\\nSiekƒÖc wrog√≥w, a Praga ju≈º siƒô wko≈Ço pali.\\nNawet stary stojƒÖcy zegar kurantowy\\nW drewnianej szafie pozna≈Ç, u wni≈õcia alkowy;\\nI z dziecinnƒÖ rado≈õciƒÖ pociƒÖgnƒÖ≈Ç za sznurek,\\nBy stary DƒÖbrowskiego us≈Çyszeƒá mazurek.\\n\\n    Biega≈Ç po ca≈Çym domu i szuka≈Ç komnaty,\\nGdzie mieszka≈Ç dzieckiem bƒôdƒÖc, przed dziesiƒôciu laty.\\nWchodzi, cofnƒÖ≈Ç siƒô, toczy≈Ç zdumione ≈∫renice\\nPo ≈õcianach: w tej komnacie mieszkanie kobi√©ce!\\nKt√≥≈º by tu mieszka≈Ç? Stary stryj nie by≈Ç ≈ºonaty;\\nA ciotka w Petersburgu mieszka≈Ça przed laty.\\nTo nie by≈Ç ochmistrzyni pok√≥j? Fortepiano?\\nNa nim nuty i ksiƒÖ≈ºki; wszystko porzucano\\nNiedbale i bez≈Çadnie: nieporzƒÖdek mi≈Çy!\\nNiestare by≈Çy rƒÖczki, co je tak rzuci≈Çy.\\nTu≈º i sukienka bia≈Ça, ≈õwie≈ºo z ko≈Çka zdjƒôta\\nDo ubrania, na krzes≈Ça porƒôczu rozpiƒôta;\\nA na oknach donice z pachnƒÖcymi zio≈Çki,\\nGeranium, lewkonija, astry i fijo≈Çki.\\nPodr√≥≈ºny stanƒÖ≈Ç w jednym z okien ‚Äî nowe dziwo:\\nW sadzie, na brzegu niegdy≈õ zaros≈Çym pokrzywƒÖ,\\nBy≈Ç male≈Ñki ogr√≥dek ≈õcie≈ºkami porzniƒôty,\\nPe≈Çen bukiet√≥w trawy angielskiej i miƒôty.\\nDrewniany, drobny, w cyfrƒô powiƒÖzany p≈Çotek\\nPo≈Çyska≈Ç siƒô wstƒÖ≈ºkami jaskrawych stokrotek;\\nGrzƒÖdki, widaƒá, ≈ºe by≈Çy ≈õwie≈ºo polewane,\\nTu≈º sta≈Ço wody pe≈Çne naczynie blaszane,\\nAle nigdzie nie widaƒá by≈Ço ogrodniczki;\\nTylko co wysz≈Ça: jeszcze ko≈ÇyszƒÖ siƒô drzwiczki\\n≈öwie≈ºo trƒÖcone, blisko drzwi ≈õlad widaƒá n√≥≈ºki\\nNa piasku, bez trzewika by≈Ça i po≈Ñczoszki;\\nNa piasku drobnym, suchym, bia≈Çym na kszta≈Çt ≈õniegu,\\n≈ölad wyra≈∫ny, lecz lekki, odgadniesz, ≈ºe w biegu\\nChybkim by≈Ç zostawiony n√≥≈ºkami drobnemi\\nOd kogo≈õ, co zaledwie dotyka≈Ç siƒô ziemi.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different ways to read files:\n",
        "1. `read()` - entire file as a single string\n",
        "2. `readlines()` - list of lines\n",
        "3. `readline()` - one line at a time"
      ],
      "metadata": {
        "id": "liwFMeIfJ3I3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Reading line by line (memory efficient for large files)\n",
        "def read_large_file(filename):\n",
        "    \"\"\"\n",
        "    Memory-efficient function to process large files line by line\n",
        "    \"\"\"\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            # Process each line\n",
        "            yield line.strip()"
      ],
      "metadata": {
        "id": "oLEX6uX7KRR4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "large_file_lines = read_large_file('/content/speech.txt')\n",
        "for line in large_file_lines:\n",
        "    print(line)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFpx_JyXvh26",
        "outputId": "6d670a3c-4138-4a37-88f3-e7a5a9dab852"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ksiƒôga pierwsza\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXERCISE 2:\n",
        "\n",
        "Create a function that:\n",
        "1. Reads a file\n",
        "2. Counts the number of lines\n",
        "3. Counts the total number of words\n",
        "4. Returns both counts"
      ],
      "metadata": {
        "id": "9yIbD9iBKSwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word_tokenize for calculating number of words"
      ],
      "metadata": {
        "id": "oEzXVwlnwKUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d7IKMayzZbO",
        "outputId": "c112f03f-7c1c-45be-a269-5e715a3ca4f1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "def file_statistics(filename):\n",
        "  number_of_lines = 0\n",
        "  number_of_words = 0\n",
        "\n",
        "  ########### HERE GOES YOUR CODE ################\n",
        "  large_file_lines = read_large_file(filename)\n",
        "  for line in large_file_lines:\n",
        "      number_of_lines += 1 # number_of_lines = number_of_lines + 1\n",
        "      number_of_words += len(word_tokenize(line))\n",
        "\n",
        "  return number_of_lines, number_of_words\n",
        "\n",
        "file_statistics('/content/speech.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgnZUbg8KZcq",
        "outputId": "76721d7a-dd1b-48df-888d-c321573755e9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114, 888)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Cleaning and Normalization"
      ],
      "metadata": {
        "id": "UAYMgWTKKedq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Basic text cleaning function\n",
        "\n",
        "    Parameters:\n",
        "    text (str): Input text\n",
        "\n",
        "    Returns:\n",
        "    str: Cleaned text\n",
        "    \"\"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "hoo-uMaIKjao"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: Working with real political text\n",
        "sample_text = \"\"\"\n",
        "The United Nations (UN) was established in 1945, after World War II.\n",
        "Its primary purpose is to maintain international peace & security.\n",
        "The UN has 193 Member States as of 2024!\n",
        "\"\"\"\n",
        "\n",
        "print(\"Original text:\")\n",
        "print(sample_text)\n",
        "print(\"\\nCleaned text:\")\n",
        "print(clean_text(sample_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KhNMCvHK1JK",
        "outputId": "7f787d23-8b3f-48e5-8c19-ffaf24abedc2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "\n",
            "The United Nations (UN) was established in 1945, after World War II. \n",
            "Its primary purpose is to maintain international peace & security.\n",
            "The UN has 193 Member States as of 2024!\n",
            "\n",
            "\n",
            "Cleaned text:\n",
            "the united nations un was established in after world war ii its primary purpose is to maintain international peace security the un has member states as of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXERCISE 3:\n",
        "\n",
        "Enhance the clean_text function to:\n",
        "1. Remove specific words (like 'the', 'and', 'or')\n",
        "2. Handle special characters\n",
        "3. Remove specific patterns (like dates, URLs)\n",
        "\n",
        "\n",
        "Write test cases for your enhanced function"
      ],
      "metadata": {
        "id": "gpmS7EI3Kfa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "def clean_text_extended(text):\n",
        "    \"\"\"\n",
        "    Basic text cleaning function\n",
        "\n",
        "    Parameters:\n",
        "    text (str): Input text\n",
        "\n",
        "    Returns:\n",
        "    str: Cleaned text\n",
        "    \"\"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Removal of urls\n",
        "    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    text = url_pattern.sub('', text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remove specific words\n",
        "    words_to_remove = ['the', 'and', 'or']\n",
        "    for word in words_to_remove:\n",
        "        text = text.replace(word, '')\n",
        "\n",
        "    # Handle special characters\n",
        "    special_characters = ['&']\n",
        "    for char in special_characters:\n",
        "        text = text.replace(char, '')\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "DmWOUplFK95R"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = 'THIS is a class of the the the or and & http://www.google.com python.'\n",
        "clean_text_extended(test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XMxiSpkP35B8",
        "outputId": "3a23105e-8cd7-4544-e3d2-edd548e0360b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this is a class of python'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parsing and Information Extraction"
      ],
      "metadata": {
        "id": "fLwpqUQULaW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_entities(text):\n",
        "    \"\"\"\n",
        "    Extract basic entities from text\n",
        "    \"\"\"\n",
        "    # Tokenize into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Tokenize into words\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    return {\n",
        "        'sentence_count': len(sentences),\n",
        "        'word_count': len(words),\n",
        "        'filtered_word_count': len(filtered_words),\n",
        "        'unique_words': len(set(filtered_words))\n",
        "    }\n"
      ],
      "metadata": {
        "id": "NbPWEWzkLp1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 4: Analyzing political text\n",
        "policy_text = \"\"\"\n",
        "The Green New Deal is a proposed package of United States legislation\n",
        "that aims to address climate change and economic inequality.\n",
        "The proposal calls for meeting 100% of the power demand in the United States\n",
        "through clean, renewable, and zero-emission energy sources.\n",
        "\"\"\"\n",
        "\n",
        "analysis = extract_entities(policy_text)\n",
        "print(\"\\nText Analysis:\")\n",
        "for key, value in analysis.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "id": "6OVAIj-1LrIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXERCISE 4:\n",
        "\n",
        "Create a function that:\n",
        "1. Takes a political text as input\n",
        "2. Identifies and counts key policy-related terms\n",
        "3. Finds the most frequent phrases (2-3 words)\n",
        "4. Returns a summary of the findings"
      ],
      "metadata": {
        "id": "HC6nB4eQLmO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "W2M7FCK6MEQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINAL PROJECT IDEAS:\n",
        "\n",
        "1. Policy Document Analyzer\n",
        "   - Read a policy document\n",
        "   - Clean and normalize the text\n",
        "   - Extract key points\n",
        "   - Generate a summary\n",
        "   - Count specific policy-related terms\n",
        "\n",
        "2. Speech Comparison Tool\n",
        "   - Read two political speeches\n",
        "   - Compare vocabulary usage\n",
        "   - Analyze sentiment\n",
        "   - Find common themes\n",
        "   - Visualize differences\n",
        "\n",
        "3. Legislative Text Processor\n",
        "   - Extract sections and subsections\n",
        "   - Find definitions\n",
        "   - Track amendments\n",
        "   - Create a searchable index"
      ],
      "metadata": {
        "id": "vkJjWrwDMHJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional Helper Functions\n",
        "\n",
        "def count_word_frequencies(text):\n",
        "    \"\"\"\n",
        "    Count word frequencies in cleaned text\n",
        "    \"\"\"\n",
        "    words = word_tokenize(clean_text(text))\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return Counter(filtered_words)\n",
        "\n",
        "def find_keywords(text, keywords):\n",
        "    \"\"\"\n",
        "    Find instances of specific keywords in text\n",
        "    \"\"\"\n",
        "    cleaned_text = clean_text(text)\n",
        "    found_keywords = {}\n",
        "    for keyword in keywords:\n",
        "        count = len(re.findall(r'\\b' + re.escape(keyword) + r'\\b', cleaned_text))\n",
        "        found_keywords[keyword] = count\n",
        "    return found_keywords\n"
      ],
      "metadata": {
        "id": "Bzfu9hhfMOjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXERCISE 5:\n",
        "\n",
        "Final Integration Exercise:\n",
        "\n",
        "Create a complete text analysis pipeline that:\n",
        "1. Reads a political document\n",
        "2. Cleans and normalizes the text\n",
        "3. Extracts key information\n",
        "4. Generates a structured report\n",
        "\n",
        "Use all the concepts we've covered in this module!"
      ],
      "metadata": {
        "id": "beCgZzTnMTMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí° TIPS & BEST PRACTICES üí°\n",
        "\n",
        "1. File Handling Tips:\n",
        "   - ALWAYS use 'with' statements when working with files (auto-closes files)\n",
        "   - ALWAYS specify encoding (usually 'utf-8') to handle special characters\n",
        "   - For large files, use generators and process line by line\n",
        "   - Keep backup copies of original files before modifying\n",
        "   - Use meaningful file names and organize by project/date\n",
        "\n",
        "2. Error Handling Tips:\n",
        "   - Wrap file operations in try-except blocks\n",
        "   - Check if file exists before operations\n",
        "   - Validate file formats and encodings\n",
        "   - Log errors for debugging\n",
        "\n",
        "3. Text Cleaning Tips:\n",
        "   - Clean text in stages, saving intermediate results\n",
        "   - Create custom cleaning functions for specific needs\n",
        "   - Document all cleaning steps for reproducibility\n",
        "   - Keep original text separate from cleaned versions\n",
        "   - Consider domain-specific cleaning needs\n",
        "\n",
        "4. Performance Tips:\n",
        "   - Use sets for fast lookups\n",
        "   - Compile regex patterns if used multiple times\n",
        "   - Use list comprehensions instead of loops where possible\n",
        "   - Process large files in chunks\n",
        "   - Use appropriate data structures (e.g., Counter for frequencies)\n",
        "\n",
        "5. Political Science-Specific Tips:\n",
        "   - Preserve proper nouns and acronyms\n",
        "   - Handle special cases like bill numbers\n",
        "   - Consider geographical references\n",
        "   - Maintain chronological markers\n",
        "   - Pay attention to political terminology\n",
        "\n",
        "6. Common Pitfalls to Avoid:\n",
        "   - Don't modify original files directly\n",
        "   - Don't assume all files are in English\n",
        "   - Don't remove all numbers (might be important)\n",
        "   - Don't forget to handle edge cases\n",
        "   - Don't clean text more than necessary"
      ],
      "metadata": {
        "id": "ai3F_uyZHi38"
      }
    }
  ]
}